import asyncio
import aiohttp
from bs4 import BeautifulSoup
import os
import random

async def get_page(url, session):
        async with session.get(url) as resp:
            soup = BeautifulSoup(await resp.text(), "lxml")
            name = soup.find_all(class_='img_block2 img_block_big')
            cnt = 0
           

            for sa in name:
                tags = sa.find('a').get('href')
                link_img = f'https://anime-pictures.net{tags}'

                async with session.get(link_img) as fa:
                    soup = BeautifulSoup(await fa.text(), 'lxml')
                    download = soup.find('div', class_='post_vote_block svelte-iczcvx')
                    w = download.find('a').get('href')

                    async with session.get(f'{w}') as img:
                        image = await img.read()
                        a = random.randint(1000, 99999999999999999999)
                        with open(f'imgsa/{a}.jpg', 'wb') as f:
                            f.write(image)
                    cnt += 1
                    
                asyncio.sleep(1)
                print(f'{link_img} - {[cnt]}')
 

async def tags():
    tasks = []
    async with aiohttp.ClientSession() as session:
        for i in range(0, 11):
            url = f'https://anime-pictures.net/posts?page={i}&lang=ru'
            task = asyncio.create_task(get_page(url, session))
            tasks.append(task)
        results = await asyncio.gather(*tasks)
        print(results)


asyncio.run(tags())
